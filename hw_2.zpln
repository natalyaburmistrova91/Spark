{
  "paragraphs": [
    {
      "title": "Как выполнять",
      "text": "%md\n.\n.\n.\nНужно скопировать себе эту тетрадку и предоставить доступ к копии на чтение, запись и запуск тетрадки пользователю admin. Параграфы с генерацией данных и созданием семплов запускать не нужно, они оставлены для ознакомления",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T11:42:32+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<p>.\n<br  />.\n<br  />.\n<br  />Нужно скопировать себе эту тетрадку и предоставить доступ к копии на чтение, запись и запуск тетрадки пользователю admin. Параграфы с генерацией данных и созданием семплов запускать не нужно, они оставлены для ознакомления</p>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352445_49503731",
      "id": "20201127-213054_1829929461",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "status": "READY",
      "focus": true,
      "$$hashKey": "object:995"
    },
    {
      "title": "Генерация events таблицы (запускать не нужно -- данные уже сгенерированы)",
      "text": "import org.apache.spark.mllib.random.RandomRDDs._\nimport java.time.LocalDate\nimport java.time.format.DateTimeFormatter\n\nval dates = (0 to 7).map(LocalDate.of(2020, 11, 1).plusDays(_).format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd\"))).toSeq\n\ndef generateCity(r: Double): String = if (r < 0.9) \"BIG_CITY\" else \"SMALL_CITY_\" + scala.math.round((r - 0.9) * 1000)\n\ndef generateCityUdf = udf(generateCity _)\n\n// spark.sql(\"drop table hw2.events_full\")\n\nfor(i <- dates) {\n    uniformRDD(sc, 10000000L, 1)\n    .toDF(\"uid\")\n    .withColumn(\"date\", lit(i))\n    .withColumn(\"city\", generateCityUdf($\"uid\"))\n    .selectExpr(\"date\", \" sha2(cast(uid as STRING), 256) event_id\", \"city\")\n    .withColumn(\"skew_key\", when($\"city\" === \"BIG_CITY\", lit(\"big_event\")).otherwise($\"event_id\"))\n    .write.mode(\"append\")\n    .partitionBy(\"date\")\n    .saveAsTable(\"hw2.events_full\")\n}\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T11:46:08+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import org.apache.spark.mllib.random.RandomRDDs._\nimport java.time.LocalDate\nimport java.time.format.DateTimeFormatter\n\u001b[1m\u001b[34mdates\u001b[0m: \u001b[1m\u001b[32mscala.collection.immutable.Seq[String]\u001b[0m = Vector(2020-11-01, 2020-11-02, 2020-11-03, 2020-11-04, 2020-11-05, 2020-11-06, 2020-11-07, 2020-11-08)\n\u001b[1m\u001b[34mgenerateCity\u001b[0m: \u001b[1m\u001b[32m(r: Double)String\u001b[0m\n\u001b[1m\u001b[34mgenerateCityUdf\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.expressions.UserDefinedFunction\u001b[0m\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_277881169",
      "id": "20201127-224038_803369215",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "status": "READY",
      "$$hashKey": "object:996"
    },
    {
      "title": "Генерация events_sample",
      "text": "spark.table(\"hw2.events_full\")\n.select(\"event_id\")\n.sample(0.0005)\n.repartition(2)\n.write.mode(\"overwrite\")\n.saveAsTable(\"hw2.sample\")\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T11:42:32+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 3,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_1044256126",
      "id": "20201127-230139_1962818180",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "status": "READY",
      "$$hashKey": "object:997"
    },
    {
      "text": "\nspark.table(\"hw2.sample\")\n.limit(100)\n.coalesce(1)\n.write.mode(\"overwrite\")\n.saveAsTable(\"hw2.sample_small\")",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T11:42:32+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 3,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_597796316",
      "id": "20201128-000812_530567540",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "status": "READY",
      "$$hashKey": "object:998"
    },
    {
      "text": "\n\nspark.table(\"hw2.events_full\")\n.select(\"event_id\")\n.sample(0.003)\n.repartition(1)\n.write.mode(\"overwrite\")\n.saveAsTable(\"hw2.sample_big\")",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T11:42:32+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 3,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_1248365350",
      "id": "20201128-091248_492627774",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "status": "READY",
      "$$hashKey": "object:999"
    },
    {
      "text": "\n\nspark.table(\"hw2.events_full\")\n.select(\"event_id\")\n.sample(0.015)\n.repartition(1)\n.write.mode(\"overwrite\")\n.saveAsTable(\"hw2.sample_very_big\")",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T11:42:32+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 3,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_784208395",
      "id": "20201128-093907_1614062530",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "status": "READY",
      "$$hashKey": "object:1000"
    },
    {
      "title": "Задание 1",
      "text": "%md\n\n\n\nДля упражнений сгрененирован большой набор синтетических данных в таблице hw2.events_full. Из этого набора данных созданы маленькие (относительно исходного набора) таблицы разного размера kotelnikov.sample_[small, big, very_big]. \n\nОтветить на вопросы:\n * какова структура таблиц\n * сколько в них записей \n * сколько места занимают данные\n ",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T11:48:52+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Для упражнений сгрененирован большой набор синтетических данных в таблице hw2.events_full. Из этого набора данных созданы маленькие (относительно исходного набора) таблицы разного размера kotelnikov.sample_[small, big, very_big].</p>\n<p>Ответить на вопросы:</p>\n<ul>\n<li>какова структура таблиц</li>\n<li>сколько в них записей</li>\n<li>сколько места занимают данные</li>\n</ul>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_1416203690",
      "id": "20201128-094640_2955666",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "dateStarted": "2021-02-05T11:48:52+0000",
      "dateFinished": "2021-02-05T11:48:52+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1001"
    },
    {
      "title": "какова структура таблиц",
      "text": "\n%pyspark\n\nspark.table(\"hw2.events_full\").show(2)\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T11:56:34+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+--------------------+-------------+--------------------+----------+\n|            event_id|         city|            skew_key|      date|\n+--------------------+-------------+--------------------+----------+\n|be5379b206e7e815b...|     BIG_CITY|           big_event|2020-11-01|\n|093774f24fcd03114...|SMALL_CITY_71|093774f24fcd03114...|2020-11-01|\n+--------------------+-------------+--------------------+----------+\nonly showing top 2 rows\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=2",
              "$$hashKey": "object:2797"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525693563_91026665",
      "id": "paragraph_1612525693563_91026665",
      "dateCreated": "2021-02-05T11:48:13+0000",
      "dateStarted": "2021-02-05T11:56:34+0000",
      "dateFinished": "2021-02-05T11:57:13+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1002"
    },
    {
      "text": "%pyspark\nspark.table(\"hw2.sample\").show(2)",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T11:57:17+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+--------------------+\n|            event_id|\n+--------------------+\n|b5a903944c5114e15...|\n|f1d7cd6880d824fdb...|\n+--------------------+\nonly showing top 2 rows\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=3",
              "$$hashKey": "object:2843"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612526035580_1345033575",
      "id": "paragraph_1612526035580_1345033575",
      "dateCreated": "2021-02-05T11:53:55+0000",
      "dateStarted": "2021-02-05T11:57:17+0000",
      "dateFinished": "2021-02-05T11:57:17+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1003"
    },
    {
      "text": "%pyspark\nspark.table(\"hw2.sample_small\").show(2)",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T11:57:40+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+--------------------+\n|            event_id|\n+--------------------+\n|b5a903944c5114e15...|\n|f1d7cd6880d824fdb...|\n+--------------------+\nonly showing top 2 rows\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=4",
              "$$hashKey": "object:2889"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612526186715_743309346",
      "id": "paragraph_1612526186715_743309346",
      "dateCreated": "2021-02-05T11:56:26+0000",
      "dateStarted": "2021-02-05T11:57:40+0000",
      "dateFinished": "2021-02-05T12:00:43+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1004"
    },
    {
      "text": "%pyspark\n\nspark.table(\"hw2.sample_big\").show(2)",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T12:01:34+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+--------------------+\n|            event_id|\n+--------------------+\n|750022833f304dca9...|\n|e59bfcb7f955b4421...|\n+--------------------+\nonly showing top 2 rows\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=5",
              "$$hashKey": "object:2935"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612526345522_1990843941",
      "id": "paragraph_1612526345522_1990843941",
      "dateCreated": "2021-02-05T11:59:05+0000",
      "dateStarted": "2021-02-05T12:01:34+0000",
      "dateFinished": "2021-02-05T12:01:34+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1005"
    },
    {
      "text": "%pyspark\n\nspark.table(\"hw2.sample_very_big\").show(2)",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T12:01:43+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+--------------------+\n|            event_id|\n+--------------------+\n|8161adf04d6dc06b3...|\n|162068e3c450fefe0...|\n+--------------------+\nonly showing top 2 rows\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=6",
              "$$hashKey": "object:2981"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612526395163_1666451201",
      "id": "paragraph_1612526395163_1666451201",
      "dateCreated": "2021-02-05T11:59:55+0000",
      "dateStarted": "2021-02-05T12:01:43+0000",
      "dateFinished": "2021-02-05T12:01:43+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1006"
    },
    {
      "text": "%md\n\nСтруктура у hw2.events_full -  event_id, city, skew_key, date\nОстальные содержат только event_id\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T13:37:26+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Структура у hw2.events_full -  event_id, city, skew_key, date<br />\nОстальные содержат только event_id</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612532177061_1680764185",
      "id": "paragraph_1612532177061_1680764185",
      "dateCreated": "2021-02-05T13:36:17+0000",
      "dateStarted": "2021-02-05T13:37:26+0000",
      "dateFinished": "2021-02-05T13:37:26+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1007"
    },
    {
      "title": "сколько в них записей",
      "text": "%pyspark\n\nprint(spark.table(\"hw2.events_full\").count())\nprint(spark.table(\"hw2.sample\").count())\nprint(spark.table(\"hw2.sample_small\").count())\nprint(spark.table(\"hw2.sample_big\").count())\nprint(spark.table(\"hw2.sample_very_big\").count())\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T13:27:15+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "110000000\n55273\n100\n330052\n1651244\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=9",
              "$$hashKey": "object:3067"
            },
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=10",
              "$$hashKey": "object:3068"
            },
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=11",
              "$$hashKey": "object:3069"
            },
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=12",
              "$$hashKey": "object:3070"
            },
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4040/jobs/job?id=13",
              "$$hashKey": "object:3071"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_868020828",
      "id": "20201224-170250_736571716",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "dateStarted": "2021-02-05T13:27:15+0000",
      "dateFinished": "2021-02-05T13:27:20+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1008"
    },
    {
      "text": "%md\n\nhw2.events_full     записей   110000000\nhw2.sample          записей       55273\nhw2.sample_small    записей         100\nhw2.sample_big      записей      330052\nhw2.sample_very_big записей     1651244\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T13:35:55+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>hw2.events_full     записей   110000000<br />\nhw2.sample          записей       55273<br />\nhw2.sample_small    записей         100<br />\nhw2.sample_big      записей      330052<br />\nhw2.sample_very_big записей     1651244</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612532053789_658832702",
      "id": "paragraph_1612532053789_658832702",
      "dateCreated": "2021-02-05T13:34:13+0000",
      "dateStarted": "2021-02-05T13:35:55+0000",
      "dateFinished": "2021-02-05T13:35:55+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1009"
    },
    {
      "title": "сколько места занимают данные",
      "text": "%sh\n\nhdfs dfs -ls /apps/spark/warehouse/hw2.db/*\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T13:38:44+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sh",
        "fontSize": 9,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Found 9 items\n-rw-r--r--   2 zeppelin hdfs          0 2021-01-22 19:29 /apps/spark/warehouse/hw2.db/events_full/_SUCCESS\ndrwxr-xr-x   - zeppelin hdfs          0 2021-01-22 19:28 /apps/spark/warehouse/hw2.db/events_full/date=2020-11-01\ndrwxr-xr-x   - zeppelin hdfs          0 2021-01-22 19:29 /apps/spark/warehouse/hw2.db/events_full/date=2020-11-02\ndrwxr-xr-x   - zeppelin hdfs          0 2021-01-22 19:29 /apps/spark/warehouse/hw2.db/events_full/date=2020-11-03\ndrwxr-xr-x   - zeppelin hdfs          0 2021-01-22 09:45 /apps/spark/warehouse/hw2.db/events_full/date=2020-11-04\ndrwxr-xr-x   - zeppelin hdfs          0 2021-01-22 09:48 /apps/spark/warehouse/hw2.db/events_full/date=2020-11-05\ndrwxr-xr-x   - zeppelin hdfs          0 2021-01-22 09:49 /apps/spark/warehouse/hw2.db/events_full/date=2020-11-06\ndrwxr-xr-x   - zeppelin hdfs          0 2021-01-22 09:49 /apps/spark/warehouse/hw2.db/events_full/date=2020-11-07\ndrwxr-xr-x   - zeppelin hdfs          0 2021-01-22 09:50 /apps/spark/warehouse/hw2.db/events_full/date=2020-11-08\nFound 7 items\n-rwxrwxrwx+  3 zeppelin hdfs          0 2020-11-28 16:13 /apps/spark/warehouse/hw2.db/events_full_skew/_SUCCESS\n-rwxrwxrwx+  3 zeppelin hdfs   30930768 2020-11-28 16:13 /apps/spark/warehouse/hw2.db/events_full_skew/part-00000-337f5177-b3df-41d8-8fd5-d56105c4a063-c000.snappy.parquet\n-rwxrwxrwx+  3 zeppelin hdfs   30842825 2020-11-28 16:13 /apps/spark/warehouse/hw2.db/events_full_skew/part-00001-337f5177-b3df-41d8-8fd5-d56105c4a063-c000.snappy.parquet\n-rwxrwxrwx+  3 zeppelin hdfs   30930791 2020-11-28 16:13 /apps/spark/warehouse/hw2.db/events_full_skew/part-00002-337f5177-b3df-41d8-8fd5-d56105c4a063-c000.snappy.parquet\n-rwxrwxrwx+  3 zeppelin hdfs   30933992 2020-11-28 16:13 /apps/spark/warehouse/hw2.db/events_full_skew/part-00003-337f5177-b3df-41d8-8fd5-d56105c4a063-c000.snappy.parquet\n-rwxrwxrwx+  3 zeppelin hdfs   30872550 2020-11-28 16:13 /apps/spark/warehouse/hw2.db/events_full_skew/part-00004-337f5177-b3df-41d8-8fd5-d56105c4a063-c000.snappy.parquet\n-rwxrwxrwx+  3 zeppelin hdfs    9341323 2020-11-28 16:13 /apps/spark/warehouse/hw2.db/events_full_skew/part-00005-337f5177-b3df-41d8-8fd5-d56105c4a063-c000.snappy.parquet\nFound 3 items\n-rw-r--r--   2 zeppelin hdfs          0 2021-01-25 10:59 /apps/spark/warehouse/hw2.db/sample/_SUCCESS\n-rw-r--r--   2 zeppelin hdfs    1761761 2021-01-25 10:59 /apps/spark/warehouse/hw2.db/sample/part-00000-0a852cec-9506-4ad7-980a-66efa789544f-c000.snappy.parquet\n-rw-r--r--   2 zeppelin hdfs    1760372 2021-01-25 10:59 /apps/spark/warehouse/hw2.db/sample/part-00001-0a852cec-9506-4ad7-980a-66efa789544f-c000.snappy.parquet\nFound 2 items\n-rw-r--r--   2 zeppelin hdfs          0 2021-01-25 11:00 /apps/spark/warehouse/hw2.db/sample_big/_SUCCESS\n-rw-r--r--   2 zeppelin hdfs   21021865 2021-01-25 11:00 /apps/spark/warehouse/hw2.db/sample_big/part-00000-c62a3867-1674-4dc2-b982-98a4c81ab6c7-c000.snappy.parquet\nFound 2 items\n-rw-r--r--   2 zeppelin hdfs          0 2021-01-25 10:59 /apps/spark/warehouse/hw2.db/sample_small/_SUCCESS\n-rw-r--r--   2 zeppelin hdfs       7218 2021-01-25 10:59 /apps/spark/warehouse/hw2.db/sample_small/part-00000-da3cfb26-7e93-412a-be46-87f9ded11569-c000.snappy.parquet\nFound 2 items\n-rw-r--r--   2 zeppelin hdfs          0 2021-01-25 11:00 /apps/spark/warehouse/hw2.db/sample_very_big/_SUCCESS\n-rw-r--r--   2 zeppelin hdfs  105171818 2021-01-25 11:00 /apps/spark/warehouse/hw2.db/sample_very_big/part-00000-f691ca81-9cce-47c3-8e6f-43ac18b9a86e-c000.snappy.parquet\nFound 2 items\n-rwxrwxrwx+  3 zeppelin hdfs          0 2020-11-28 16:13 /apps/spark/warehouse/hw2.db/skew_key_sample/_SUCCESS\n-rwxrwxrwx+  3 zeppelin hdfs      11623 2020-11-28 16:13 /apps/spark/warehouse/hw2.db/skew_key_sample/part-00000-01ead553-7d40-43cc-b189-44d12a4f11d8-c000.snappy.parquet\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_466450577",
      "id": "20201224-170354_2027076678",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "dateStarted": "2021-02-05T13:38:44+0000",
      "dateFinished": "2021-02-05T13:38:46+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1010"
    },
    {
      "text": "%sh\n\nhdfs dfs -du -s -h /apps/spark/warehouse/hw2.db/*",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T13:33:13+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sh",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "7.3 G    14.6 G   /apps/spark/warehouse/hw2.db/events_full\n156.3 M  468.8 M  /apps/spark/warehouse/hw2.db/events_full_skew\n3.4 M    6.7 M    /apps/spark/warehouse/hw2.db/sample\n20.0 M   40.1 M   /apps/spark/warehouse/hw2.db/sample_big\n7.0 K    14.1 K   /apps/spark/warehouse/hw2.db/sample_small\n100.3 M  200.6 M  /apps/spark/warehouse/hw2.db/sample_very_big\n11.4 K   34.1 K   /apps/spark/warehouse/hw2.db/skew_key_sample\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612531880130_13387845",
      "id": "paragraph_1612531880130_13387845",
      "dateCreated": "2021-02-05T13:31:20+0000",
      "dateStarted": "2021-02-05T13:33:13+0000",
      "dateFinished": "2021-02-05T13:33:15+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1011"
    },
    {
      "text": "%md\n\nУ самой большой таблицы - 8 партиций, занимает 7.3 G    14.6 G\nУ sample 2 партиции 3.4 M    6.7 M \nу small, big, very big по 1. Small - 7.0 K    14.1 K, big - 20.0 M   40.1 M, very_big - 100.3 M  200.6 M\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T13:47:38+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>У самой большой таблицы - 8 партиций, занимает 7.3 G    14.6 G<br />\nУ sample 2 партиции 3.4 M    6.7 M<br />\nу small, big, very big по 1. Small - 7.0 K    14.1 K, big - 20.0 M   40.1 M, very_big - 100.3 M  200.6 M</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612532331507_1217735135",
      "id": "paragraph_1612532331507_1217735135",
      "dateCreated": "2021-02-05T13:38:51+0000",
      "dateStarted": "2021-02-05T13:47:38+0000",
      "dateFinished": "2021-02-05T13:47:38+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1012"
    },
    {
      "title": "Задание 2",
      "text": "%md\n.\n.\n.\n\nПолучить планы запросов для джойна большой таблицы hw2.events_full с каждой из таблиц hw2.sample, hw2.sample_big, hw2.sample_very_big по полю event_id. В каких случаях используется BroadcastHashJoin? \n\nBroadcastHashJoin автоматически выполняется для джойна с таблицами, размером меньше параметра spark.sql.autoBroadcastJoinThreshold. Узнать его значение можно командой spark.conf.get(\"spark.sql.autoBroadcastJoinThreshold\").",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T14:49:35+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>.<br />\n.<br />\n.</p>\n<p>Получить планы запросов для джойна большой таблицы hw2.events_full с каждой из таблиц hw2.sample, hw2.sample_big, hw2.sample_very_big по полю event_id. В каких случаях используется BroadcastHashJoin?</p>\n<p>BroadcastHashJoin автоматически выполняется для джойна с таблицами, размером меньше параметра spark.sql.autoBroadcastJoinThreshold. Узнать его значение можно командой spark.conf.get(&ldquo;spark.sql.autoBroadcastJoinThreshold&rdquo;).</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_318203699",
      "id": "20201128-132950_831220047",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "dateStarted": "2021-02-05T14:49:35+0000",
      "dateFinished": "2021-02-05T14:49:35+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1013"
    },
    {
      "text": "spark.conf.get(\"spark.sql.autoBroadcastJoinThreshold\")",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T14:21:22+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mres1\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = 26214400\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612534818511_1714693387",
      "id": "paragraph_1612534818511_1714693387",
      "dateCreated": "2021-02-05T14:20:18+0000",
      "dateStarted": "2021-02-05T14:21:22+0000",
      "dateFinished": "2021-02-05T14:21:23+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1014"
    },
    {
      "text": "%pyspark\n\ndf_ef = spark.table(\"hw2.events_full\")\ndf_s = spark.table(\"hw2.sample\")\ndf_s_sm = spark.table(\"hw2.sample_small\")\ndf_s_b = spark.table(\"hw2.sample_big\")\ndf_s_vb = spark.table(\"hw2.sample_very_big\")\n# df_ef.printSchema()\n# df_ef.show()",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T17:44:45+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Hive Session ID = 899d5390-51db-4144-b410-d702549b030c\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612535735595_309695050",
      "id": "paragraph_1612535735595_309695050",
      "dateCreated": "2021-02-05T14:35:35+0000",
      "dateStarted": "2021-02-05T17:44:45+0000",
      "dateFinished": "2021-02-05T17:45:16+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1015"
    },
    {
      "title": "hw2.events_full с hw2.sample",
      "text": "%pyspark\n\ndf_ef.join(df_s, \"event_id\").explain()",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T14:50:02+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "== Physical Plan ==\n*(2) Project [event_id#0, city#1, skew_key#2, date#3]\n+- *(2) BroadcastHashJoin [event_id#0], [event_id#26], Inner, BuildRight\n   :- *(2) Project [event_id#0, city#1, skew_key#2, date#3]\n   :  +- *(2) Filter isnotnull(event_id#0)\n   :     +- *(2) FileScan parquet hw2.events_full[event_id#0,city#1,skew_key#2,date#3] Batched: true, Format: Parquet, Location: CatalogFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/events..., PartitionCount: 8, PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string,city:string,skew_key:string>\n   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))\n      +- *(1) Project [event_id#26]\n         +- *(1) Filter isnotnull(event_id#26)\n            +- *(1) FileScan parquet hw2.sample[event_id#26] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/sample], PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_904563234",
      "id": "20201224-171235_110184756",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "dateStarted": "2021-02-05T14:50:02+0000",
      "dateFinished": "2021-02-05T14:50:02+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1016"
    },
    {
      "title": "hw2.events_full с hw2.sample_big",
      "text": "%pyspark\n\ndf_ef.join(df_s_b, \"event_id\").explain()\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T14:50:30+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "== Physical Plan ==\n*(2) Project [event_id#0, city#1, skew_key#2, date#3]\n+- *(2) BroadcastHashJoin [event_id#0], [event_id#30], Inner, BuildRight\n   :- *(2) Project [event_id#0, city#1, skew_key#2, date#3]\n   :  +- *(2) Filter isnotnull(event_id#0)\n   :     +- *(2) FileScan parquet hw2.events_full[event_id#0,city#1,skew_key#2,date#3] Batched: true, Format: Parquet, Location: CatalogFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/events..., PartitionCount: 8, PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string,city:string,skew_key:string>\n   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))\n      +- *(1) Project [event_id#30]\n         +- *(1) Filter isnotnull(event_id#30)\n            +- *(1) FileScan parquet hw2.sample_big[event_id#30] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/sampl..., PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612536487184_61035318",
      "id": "paragraph_1612536487184_61035318",
      "dateCreated": "2021-02-05T14:48:07+0000",
      "dateStarted": "2021-02-05T14:50:30+0000",
      "dateFinished": "2021-02-05T14:50:30+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1017"
    },
    {
      "title": "hw2.events_full с hw2.sample_very_big",
      "text": "%pyspark\n\ndf_ef.join(df_s_vb, \"event_id\").explain()\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T14:52:54+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "== Physical Plan ==\n*(5) Project [event_id#0, city#1, skew_key#2, date#3]\n+- *(5) SortMergeJoin [event_id#0], [event_id#32], Inner\n   :- *(2) Sort [event_id#0 ASC NULLS FIRST], false, 0\n   :  +- Exchange hashpartitioning(event_id#0, 200)\n   :     +- *(1) Project [event_id#0, city#1, skew_key#2, date#3]\n   :        +- *(1) Filter isnotnull(event_id#0)\n   :           +- *(1) FileScan parquet hw2.events_full[event_id#0,city#1,skew_key#2,date#3] Batched: true, Format: Parquet, Location: CatalogFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/events..., PartitionCount: 8, PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string,city:string,skew_key:string>\n   +- *(4) Sort [event_id#32 ASC NULLS FIRST], false, 0\n      +- Exchange hashpartitioning(event_id#32, 200)\n         +- *(3) Project [event_id#32]\n            +- *(3) Filter isnotnull(event_id#32)\n               +- *(3) FileScan parquet hw2.sample_very_big[event_id#32] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/sampl..., PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612536493235_1360541028",
      "id": "paragraph_1612536493235_1360541028",
      "dateCreated": "2021-02-05T14:48:13+0000",
      "dateStarted": "2021-02-05T14:51:00+0000",
      "dateFinished": "2021-02-05T14:51:00+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1018"
    },
    {
      "text": "%md\n\nпри Join hw2.events_full с hw2.sample_very_big не использовался broadcast. В таблицах меньших размеров - использовался\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T14:54:03+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>при Join hw2.events_full с hw2.sample_very_big не использовался broadcast. В таблицах меньших размеров - использовался</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612536759417_782222350",
      "id": "paragraph_1612536759417_782222350",
      "dateCreated": "2021-02-05T14:52:39+0000",
      "dateStarted": "2021-02-05T14:54:03+0000",
      "dateFinished": "2021-02-05T14:54:03+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1019"
    },
    {
      "title": "Задание 3",
      "text": "%md\n.\n.\n.\n\nВыполнить джойны с таблицами  hw2.sample,  hw2.sample_big в отдельных параграфах, чтобы узнать время выполнения запросов (например, вызвать .count() для результатов запросов). Время выполнения параграфа считается автоматически и указывается в нижней части по завершении\n ",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T15:06:06+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>.<br />\n.<br />\n.</p>\n<p>Выполнить джойны с таблицами  hw2.sample,  hw2.sample_big в отдельных параграфах, чтобы узнать время выполнения запросов (например, вызвать .count() для результатов запросов). Время выполнения параграфа считается автоматически и указывается в нижней части по завершении</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_440563041",
      "id": "20201128-140231_1065047171",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "dateStarted": "2021-02-05T15:06:06+0000",
      "dateFinished": "2021-02-05T15:06:06+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1020"
    },
    {
      "text": "spark.table(\"hw2.events_full\").rdd.partitions.size",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T17:24:22+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mres2\u001b[0m: \u001b[1m\u001b[32mInt\u001b[0m = 60\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612545857400_1383792893",
      "id": "paragraph_1612545857400_1383792893",
      "dateCreated": "2021-02-05T17:24:17+0000",
      "dateStarted": "2021-02-05T17:24:22+0000",
      "dateFinished": "2021-02-05T17:24:23+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1021"
    },
    {
      "text": "%pyspark\n\ndf_ef.join(df_s, \"event_id\").count()\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T16:39:22+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "55273\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4041/jobs/job?id=0",
              "$$hashKey": "object:3653"
            },
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4041/jobs/job?id=1",
              "$$hashKey": "object:3654"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612537204543_1368568999",
      "id": "paragraph_1612537204543_1368568999",
      "dateCreated": "2021-02-05T15:00:04+0000",
      "dateStarted": "2021-02-05T16:39:22+0000",
      "dateFinished": "2021-02-05T16:40:15+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1022"
    },
    {
      "text": "%pyspark\n\ndf_ef.join(df_s_b, \"event_id\").count()\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T15:04:34+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "330052\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4041/jobs/job?id=4",
              "$$hashKey": "object:3704"
            },
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4041/jobs/job?id=5",
              "$$hashKey": "object:3705"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_947826350",
      "id": "20201224-171618_470251701",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "dateStarted": "2021-02-05T15:04:34+0000",
      "dateFinished": "2021-02-05T15:05:23+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1023"
    },
    {
      "text": "%pyspark\n\ndf_ef.join(df_s_vb, \"event_id\").count()",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T17:29:21+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "1651244\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4041/jobs/job?id=6",
              "$$hashKey": "object:3755"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612537719222_696149679",
      "id": "paragraph_1612537719222_696149679",
      "dateCreated": "2021-02-05T15:08:39+0000",
      "dateStarted": "2021-02-05T15:08:53+0000",
      "dateFinished": "2021-02-05T15:11:29+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1024"
    },
    {
      "text": "%md\n\nджойны с таблицами  hw2.sample - 52 секунды, с hw2.sample_big - 49, very big - 2.6 min\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T15:15:58+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>джойны с таблицами  hw2.sample - 52 секунды, с hw2.sample_big - 49, very big - 2.6 min</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612537527994_985091473",
      "id": "paragraph_1612537527994_985091473",
      "dateCreated": "2021-02-05T15:05:27+0000",
      "dateStarted": "2021-02-05T15:15:58+0000",
      "dateFinished": "2021-02-05T15:15:58+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1025"
    },
    {
      "text": "%md\nСколько tasks создано на каждую операцию? \n\nджойны с таблицами  hw2.sample - 63 task, с hw2.sample_big - 63 task, very big = 263",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T17:29:54+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Сколько tasks создано на каждую операцию?</p>\n<p>джойны с таблицами  hw2.sample - 63 task, с hw2.sample_big - 63 task, very big = 263</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612537763163_1558078504",
      "id": "paragraph_1612537763163_1558078504",
      "dateCreated": "2021-02-05T15:09:23+0000",
      "dateStarted": "2021-02-05T17:29:54+0000",
      "dateFinished": "2021-02-05T17:29:54+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1026"
    },
    {
      "text": "%md\n\nПочему именно столько? \n63 = 2 tasks с запуском экзекьютора, 60 для подсчета в каждой партиции events_full и 1 для подсчета общего результата.\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T17:25:26+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Почему именно столько?<br />\n63 = 2 tasks с запуском экзекьютора, 60 для подсчета в каждой партиции events_full и 1 для подсчета общего результата.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612538126733_531656508",
      "id": "paragraph_1612538126733_531656508",
      "dateCreated": "2021-02-05T15:15:26+0000",
      "dateStarted": "2021-02-05T17:25:26+0000",
      "dateFinished": "2021-02-05T17:25:26+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1027"
    },
    {
      "text": "%md\n\nКаков DAG вычислений?\n\nУ hw2.sample и hw2.sample_big по 2 stage. в 1 - WholeStageCodegen (FileScanRDD [3]count at NativeMethodAccessorImpl.java:0 - > count at NativeMethodAccessorImpl.java:0) и MapPartitionsRDD [5]count at NativeMethodAccessorImpl.java:0 (60 task). Во 2 - ShuffledRowRDD [6]count at NativeMethodAccessorImpl.java:0 -> MapPartitionsRDD [7]count at NativeMethodAccessorImpl.java:0 - > MapPartitionsRDD [8]count at NativeMethodAccessorImpl.java:0 (1 task)",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T17:25:48+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Каков DAG вычислений?</p>\n<p>У hw2.sample и hw2.sample_big по 2 stage. в 1 - WholeStageCodegen (FileScanRDD [3]count at NativeMethodAccessorImpl.java:0 - &gt; count at NativeMethodAccessorImpl.java:0) и MapPartitionsRDD [5]count at NativeMethodAccessorImpl.java:0 (60 task). Во 2 - ShuffledRowRDD [6]count at NativeMethodAccessorImpl.java:0 -&gt; MapPartitionsRDD [7]count at NativeMethodAccessorImpl.java:0 - &gt; MapPartitionsRDD [8]count at NativeMethodAccessorImpl.java:0 (1 task)</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612538142960_524189291",
      "id": "paragraph_1612538142960_524189291",
      "dateCreated": "2021-02-05T15:15:42+0000",
      "dateStarted": "2021-02-05T17:25:48+0000",
      "dateFinished": "2021-02-05T17:25:48+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1028"
    },
    {
      "title": "Генерация ссылки на  spark UI",
      "text": "println(\"185.241.193.174:8088/proxy/\" + sc.applicationId + \"/jobs/\")",
      "user": "393_burmistrova",
      "dateUpdated": "2021-02-09T14:10:30+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "185.241.193.174:8088/proxy/application_1612470347159_0170/jobs/\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_101902591",
      "id": "20201128-150602_756898802",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "dateStarted": "2021-02-09T14:10:30+0000",
      "dateFinished": "2021-02-09T14:10:30+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1029"
    },
    {
      "title": "Насильный broadcast",
      "text": "%md\n\nОптимизировать джойн с таблицами hw2.sample_big, hw2.sample_very_big с помощью broadcast(df). Выполнить запрос, посмотреть в UI, как поменялся план запроса, DAG, количество тасков. Второй запрос не выполнится ",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T11:42:32+0000",
      "progress": 0,
      "config": {
        "tableHide": true,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<p>Оптимизировать джойн с таблицами hw2.sample_big, hw2.sample_very_big с помощью broadcast(df). Выполнить запрос, посмотреть в UI, как поменялся план запроса, DAG, количество тасков. Второй запрос не выполнится</p>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_1799995582",
      "id": "20201128-140749_375295552",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "status": "READY",
      "$$hashKey": "object:1030"
    },
    {
      "text": "%pyspark\nfrom pyspark.sql.functions import broadcast\n\ndf_ef.join(broadcast(df_s_b), \"event_id\").count()",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T17:37:42+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "330052\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4041/jobs/job?id=6",
              "$$hashKey": "object:4041"
            },
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4041/jobs/job?id=7",
              "$$hashKey": "object:4042"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612546074641_1480202437",
      "id": "paragraph_1612546074641_1480202437",
      "dateCreated": "2021-02-05T17:27:54+0000",
      "dateStarted": "2021-02-05T17:37:42+0000",
      "dateFinished": "2021-02-05T17:38:32+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1031"
    },
    {
      "text": "%pyspark\n\ndf_ef.join(broadcast(df_s_vb), \"event_id\").count()\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T17:38:48+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "Exception in thread \"pool-3-thread-1\" java.lang.OutOfMemoryError: GC overhead limit exceeded\nException in thread \"broadcast-exchange-4\" Exception in thread \"spark-listener-group-streams\" java.lang.OutOfMemoryError: Not enough memory to build and broadcast the table to all worker nodes. As a workaround, you can either disable broadcast by setting spark.sql.autoBroadcastJoinThreshold to -1 or increase the spark driver memory by setting spark.driver.memory to a higher value\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec$$anonfun$relationFuture$1$$anonfun$apply$1.apply(BroadcastExchangeExec.scala:115)\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec$$anonfun$relationFuture$1$$anonfun$apply$1.apply(BroadcastExchangeExec.scala:73)\n\tat org.apache.spark.sql.execution.SQLExecution$.withExecutionId(SQLExecution.scala:97)\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec$$anonfun$relationFuture$1.apply(BroadcastExchangeExec.scala:72)\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec$$anonfun$relationFuture$1.apply(BroadcastExchangeExec.scala:72)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n"
          },
          {
            "type": "TEXT",
            "data": "Py4JJavaError: An error occurred while calling o166.count.\n: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:\nExchange SinglePartition\n+- *(2) HashAggregate(keys=[], functions=[partial_count(1)], output=[count#87L])\n   +- *(2) Project\n      +- *(2) BroadcastHashJoin [event_id#0], [event_id#14], Inner, BuildRight\n         :- *(2) Project [event_id#0]\n         :  +- *(2) Filter isnotnull(event_id#0)\n         :     +- *(2) FileScan parquet hw2.events_full[event_id#0,date#3] Batched: true, Format: Parquet, Location: CatalogFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/events..., PartitionCount: 8, PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string>\n         +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))\n            +- *(1) Project [event_id#14]\n               +- *(1) Filter isnotnull(event_id#14)\n                  +- *(1) FileScan parquet hw2.sample_very_big[event_id#14] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://bigdataanalytics-head-0.novalocal:8020/apps/spark/warehouse/hw2.db/sampl..., PartitionFilters: [], PushedFilters: [IsNotNull(event_id)], ReadSchema: struct<event_id:string>\n\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:56)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:371)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:150)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:247)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:294)\n\tat org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2775)\n\tat org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2774)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3259)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3258)\n\tat org.apache.spark.sql.Dataset.count(Dataset.scala:2774)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.util.concurrent.TimeoutException: Futures timed out after [300 seconds]\n\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:223)\n\tat scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:227)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.doExecuteBroadcast(BroadcastExchangeExec.scala:136)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecuteBroadcast(WholeStageCodegenExec.scala:367)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeBroadcast$1.apply(SparkPlan.scala:144)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeBroadcast$1.apply(SparkPlan.scala:140)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.executeBroadcast(SparkPlan.scala:140)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.prepareBroadcast(BroadcastHashJoinExec.scala:135)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.codegenInner(BroadcastHashJoinExec.scala:232)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doConsume(BroadcastHashJoinExec.scala:102)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.constructDoConsumeFunction(WholeStageCodegenExec.scala:208)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.consume(WholeStageCodegenExec.scala:179)\n\tat org.apache.spark.sql.execution.ProjectExec.consume(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.ProjectExec.doConsume(basicPhysicalOperators.scala:65)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.consume(WholeStageCodegenExec.scala:181)\n\tat org.apache.spark.sql.execution.FilterExec.consume(basicPhysicalOperators.scala:85)\n\tat org.apache.spark.sql.execution.FilterExec.doConsume(basicPhysicalOperators.scala:206)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.consume(WholeStageCodegenExec.scala:181)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.consume(DataSourceScanExec.scala:158)\n\tat org.apache.spark.sql.execution.ColumnarBatchScan$class.produceBatches(ColumnarBatchScan.scala:138)\n\tat org.apache.spark.sql.execution.ColumnarBatchScan$class.doProduce(ColumnarBatchScan.scala:78)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.doProduce(DataSourceScanExec.scala:158)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.produce(DataSourceScanExec.scala:158)\n\tat org.apache.spark.sql.execution.FilterExec.doProduce(basicPhysicalOperators.scala:125)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)\n\tat org.apache.spark.sql.execution.FilterExec.produce(basicPhysicalOperators.scala:85)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:97)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:39)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:45)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:35)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.doProduceWithoutKeys(HashAggregateExec.scala:234)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.doProduce(HashAggregateExec.scala:163)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:88)\n\tat org.apache.spark.sql.execution.CodegenSupport$$anonfun$produce$1.apply(WholeStageCodegenExec.scala:83)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.CodegenSupport$class.produce(WholeStageCodegenExec.scala:83)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.produce(HashAggregateExec.scala:39)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doCodeGen(WholeStageCodegenExec.scala:524)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:576)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:92)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\t... 35 more\n\n(<class 'py4j.protocol.Py4JJavaError'>, Py4JJavaError(u'An error occurred while calling o166.count.\\n', JavaObject id=o167), <traceback object at 0x7f7217748638>)"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4041/jobs/job?id=8",
              "$$hashKey": "object:4092"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612546262099_2027816661",
      "id": "paragraph_1612546262099_2027816661",
      "dateCreated": "2021-02-05T17:31:02+0000",
      "dateStarted": "2021-02-05T17:38:48+0000",
      "dateFinished": "2021-02-05T17:43:48+0000",
      "status": "ERROR",
      "$$hashKey": "object:1032"
    },
    {
      "text": "%md\n\nПервый запрос отработал как в первый раз, а для sample_very_big вышла ошибка increase the spark driver memory - не хватило памяти",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T17:40:09+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Первый запрос отработал как в первый раз, а для sample_very_big вышла ошибка increase the spark driver memory - не хватило памяти</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612546741865_1881838555",
      "id": "paragraph_1612546741865_1881838555",
      "dateCreated": "2021-02-05T17:39:01+0000",
      "dateStarted": "2021-02-05T17:40:09+0000",
      "dateFinished": "2021-02-05T17:40:09+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1033"
    },
    {
      "title": "Отключение auto broadcast",
      "text": "%md\n.\n.\n.\n\nОтключить автоматический броадкаст командой spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\"). Сделать джойн с семплом hw2.sample, сравнить время выполнения запроса.\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T17:41:05+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>.<br />\n.<br />\n.</p>\n<p>Отключить автоматический броадкаст командой spark.conf.set(&ldquo;spark.sql.autoBroadcastJoinThreshold&rdquo;, &ldquo;-1&rdquo;). Сделать джойн с семплом hw2.sample, сравнить время выполнения запроса.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_1756429939",
      "id": "20201128-092252_410955057",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "dateStarted": "2021-02-05T17:41:05+0000",
      "dateFinished": "2021-02-05T17:41:05+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1034"
    },
    {
      "text": "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T17:45:28+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612546842341_1759170215",
      "id": "paragraph_1612546842341_1759170215",
      "dateCreated": "2021-02-05T17:40:42+0000",
      "dateStarted": "2021-02-05T17:45:28+0000",
      "dateFinished": "2021-02-05T17:45:28+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1035"
    },
    {
      "text": "%pyspark\n\ndf_ef.join(df_s, \"event_id\").count()",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T17:45:33+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "55273\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4041/jobs/job?id=0",
              "$$hashKey": "object:4258"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612546874310_200452436",
      "id": "paragraph_1612546874310_200452436",
      "dateCreated": "2021-02-05T17:41:14+0000",
      "dateStarted": "2021-02-05T17:45:33+0000",
      "dateFinished": "2021-02-05T17:48:32+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1036"
    },
    {
      "text": "%md время выполнения увеличилось более чем в 3 раза",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T17:48:54+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>время выполнения увеличилось более чем в 3 раза</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612546960056_867950689",
      "id": "paragraph_1612546960056_867950689",
      "dateCreated": "2021-02-05T17:42:40+0000",
      "dateStarted": "2021-02-05T17:48:54+0000",
      "dateFinished": "2021-02-05T17:48:56+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1037"
    },
    {
      "title": "Вернуть настройку к исходной",
      "text": "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"26214400\")",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T17:49:06+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_902489846",
      "id": "20201127-230625_1272901030",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "dateStarted": "2021-02-05T17:49:06+0000",
      "dateFinished": "2021-02-05T17:49:06+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1038"
    },
    {
      "text": "spark.sql(\"clear cache\")",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T17:49:18+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mres3\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = []\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_605892922",
      "id": "20201128-155645_947820002",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "dateStarted": "2021-02-05T17:49:18+0000",
      "dateFinished": "2021-02-05T17:49:19+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1039"
    },
    {
      "title": "Задание 4",
      "text": "%md\n.\n.\n.\n\nВ процессе обработки данных может возникнуть перекос объёма партиций по количеству данных (data skew). В таком случае время выполнения запроса может существенно увеличиться, так как данные распределятся по исполнителям неравномерно. В следующем параграфе происходит инициализация датафрейма, этот параграф нужно выполнить, изменять код нельзя. В задании нужно работать с инициализированным датафреймом.\n\nДатафрейм разделен на 30 партиций по ключу city, который имеет сильно  неравномерное распределение.",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T11:42:32+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<p>.\n<br  />.\n<br  />.</p>\n<p>В процессе обработки данных может возникнуть перекос объёма партиций по количеству данных (data skew). В таком случае время выполнения запроса может существенно увеличиться, так как данные распределятся по исполнителям неравномерно. В следующем параграфе происходит инициализация датафрейма, этот параграф нужно выполнить, изменять код нельзя. В задании нужно работать с инициализированным датафреймом.</p>\n<p>Датафрейм разделен на 30 партиций по ключу city, который имеет сильно  неравномерное распределение.</p>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_2108979077",
      "id": "20201128-163357_1545019956",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "status": "READY",
      "$$hashKey": "object:1040"
    },
    {
      "title": "нужно выполнить, изменять код нельзя",
      "text": "%pyspark \nfrom pyspark.sql.functions import col\n\nskew_df = spark.table(\"hw2.events_full\")\\\n.where(\"date = '2020-11-01'\")\\\n.repartition(30, col(\"city\"))\\\n.cache()\n\nskew_df.count()",
      "user": "393_burmistrova",
      "dateUpdated": "2021-02-09T14:04:25+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Hive Session ID = 03c1396c-d145-4070-be05-edbee84947ea\n20000000\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4042/jobs/job?id=0",
              "$$hashKey": "object:5353"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_983097425",
      "id": "20201128-162744_575252973",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1041",
      "dateFinished": "2021-02-09T14:06:21+0000",
      "dateStarted": "2021-02-09T14:04:25+0000"
    },
    {
      "title": "4.1. Наблюдение проблемы",
      "text": "%md\n.\n.\n.\n\nПосчитать количество event_count различных событий event_id , содержащихся в skew_df с группировкой по городам. Результат упорядочить по event_count.\n\nВ spark ui в разделе jobs выбрать последнюю, в ней зайти в stage, состоящую из 30 тасков (из такого количества партиций состоит skew_df). На странице стейджа нажать кнопку Event Timeline и увидеть время выполнения тасков по экзекьюторам. Одному из них выпала партиция с существенно большим количеством данных. Остальные экзекьюторы в это время бездействуют -- это и является проблемой, которую предлагается решить далее.",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T11:42:32+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<p>.\n<br  />.\n<br  />.</p>\n<p>Посчитать количество event_count различных событий event_id , содержащихся в skew_df с группировкой по городам. Результат упорядочить по event_count.</p>\n<p>В spark ui в разделе jobs выбрать последнюю, в ней зайти в stage, состоящую из 30 тасков (из такого количества партиций состоит skew_df). На странице стейджа нажать кнопку Event Timeline и увидеть время выполнения тасков по экзекьюторам. Одному из них выпала партиция с существенно большим количеством данных. Остальные экзекьюторы в это время бездействуют &ndash; это и является проблемой, которую предлагается решить далее.</p>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_1119047771",
      "id": "20201128-164139_1371291032",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "status": "READY",
      "$$hashKey": "object:1042"
    },
    {
      "text": "%pyspark\n\nskew_df.show(2)",
      "user": "393_burmistrova",
      "dateUpdated": "2021-02-09T14:09:15+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4042/jobs/job?id=2",
              "$$hashKey": "object:5584"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612879734869_1259530721",
      "id": "paragraph_1612879734869_1259530721",
      "dateCreated": "2021-02-09T14:08:54+0000",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:5359",
      "dateFinished": "2021-02-09T14:09:15+0000",
      "dateStarted": "2021-02-09T14:09:15+0000",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+--------------------+-------------+--------------------+----------+\n|            event_id|         city|            skew_key|      date|\n+--------------------+-------------+--------------------+----------+\n|bfe3a0110ab910ecd...|SMALL_CITY_40|bfe3a0110ab910ecd...|2020-11-01|\n|041b4b5d6d31e2ef5...|SMALL_CITY_66|041b4b5d6d31e2ef5...|2020-11-01|\n+--------------------+-------------+--------------------+----------+\nonly showing top 2 rows\n\n"
          }
        ]
      }
    },
    {
      "text": "%pyspark\n\n\nskew_df\\\n    .groupBy(\"city\")\\\n    .count()\\\n    .orderBy(col(\"count\"))\\\n    .show()",
      "user": "393_burmistrova",
      "dateUpdated": "2021-02-09T14:09:54+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4042/jobs/job?id=3",
              "$$hashKey": "object:5635"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612879751411_623873448",
      "id": "paragraph_1612879751411_623873448",
      "dateCreated": "2021-02-09T14:09:11+0000",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:5470",
      "dateFinished": "2021-02-09T14:10:00+0000",
      "dateStarted": "2021-02-09T14:09:54+0000",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+--------------+-----+\n|          city|count|\n+--------------+-----+\n|SMALL_CITY_100| 9917|\n|  SMALL_CITY_0| 9964|\n| SMALL_CITY_54|19683|\n| SMALL_CITY_39|19695|\n| SMALL_CITY_45|19704|\n| SMALL_CITY_40|19717|\n| SMALL_CITY_14|19732|\n| SMALL_CITY_10|19744|\n| SMALL_CITY_16|19761|\n| SMALL_CITY_50|19768|\n| SMALL_CITY_80|19775|\n| SMALL_CITY_21|19788|\n| SMALL_CITY_58|19790|\n| SMALL_CITY_17|19815|\n| SMALL_CITY_69|19818|\n| SMALL_CITY_84|19825|\n| SMALL_CITY_83|19834|\n| SMALL_CITY_23|19835|\n|  SMALL_CITY_2|19844|\n| SMALL_CITY_74|19852|\n+--------------+-----+\nonly showing top 20 rows\n\n"
          }
        ]
      }
    },
    {
      "title": "4.2. repartition",
      "text": "%md\n.\n.\n.\n\nодин из способов решения проблемы агрегации по неравномерно распределенному ключу является предварительное перемешивание данных. Его можно сделать с помощью метода repartition(p_num), где p_num -- количество партиций, на которые будет перемешан исходный датафрейм",
      "user": "393_burmistrova",
      "dateUpdated": "2021-02-09T14:21:33+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>.<br />\n.<br />\n.</p>\n<p>один из способов решения проблемы агрегации по неравномерно распределенному ключу является предварительное перемешивание данных. Его можно сделать с помощью метода repartition(p_num), где p_num &ndash; количество партиций, на которые будет перемешан исходный датафрейм</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_799660609",
      "id": "20201128-164814_1641460265",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1043",
      "dateFinished": "2021-02-09T14:21:33+0000",
      "dateStarted": "2021-02-09T14:21:33+0000"
    },
    {
      "text": "%pyspark\r\n\r\nskew_df_r = skew_df.repartition(30)",
      "user": "393_burmistrova",
      "dateUpdated": "2021-02-09T14:19:28+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612879985188_377167857",
      "id": "paragraph_1612879985188_377167857",
      "dateCreated": "2021-02-09T14:13:05+0000",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:5679",
      "dateFinished": "2021-02-09T14:19:28+0000",
      "dateStarted": "2021-02-09T14:19:28+0000",
      "results": {
        "code": "SUCCESS",
        "msg": []
      }
    },
    {
      "text": "%pyspark\n\nskew_df_r\\\n    .groupBy(\"city\")\\\n    .count()\\\n    .orderBy(col(\"count\"))\\\n    .show()",
      "user": "393_burmistrova",
      "dateUpdated": "2021-02-09T14:19:40+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4042/jobs/job?id=6",
              "$$hashKey": "object:5964"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612880268210_657072627",
      "id": "paragraph_1612880268210_657072627",
      "dateCreated": "2021-02-09T14:17:48+0000",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:5754",
      "dateFinished": "2021-02-09T14:20:00+0000",
      "dateStarted": "2021-02-09T14:19:40+0000",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+--------------+-----+\n|          city|count|\n+--------------+-----+\n|SMALL_CITY_100| 9917|\n|  SMALL_CITY_0| 9964|\n| SMALL_CITY_54|19683|\n| SMALL_CITY_39|19695|\n| SMALL_CITY_45|19704|\n| SMALL_CITY_40|19717|\n| SMALL_CITY_14|19732|\n| SMALL_CITY_10|19744|\n| SMALL_CITY_16|19761|\n| SMALL_CITY_50|19768|\n| SMALL_CITY_80|19775|\n| SMALL_CITY_21|19788|\n| SMALL_CITY_58|19790|\n| SMALL_CITY_17|19815|\n| SMALL_CITY_69|19818|\n| SMALL_CITY_84|19825|\n| SMALL_CITY_83|19834|\n| SMALL_CITY_23|19835|\n|  SMALL_CITY_2|19844|\n| SMALL_CITY_74|19852|\n+--------------+-----+\nonly showing top 20 rows\n\n"
          }
        ]
      }
    },
    {
      "text": "%md\n\n\nпосле repartition распределение более равномерное по времени\n",
      "user": "393_burmistrova",
      "dateUpdated": "2021-02-09T14:22:12+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612880465347_741821694",
      "id": "paragraph_1612880465347_741821694",
      "dateCreated": "2021-02-09T14:21:05+0000",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:5967",
      "dateFinished": "2021-02-09T14:22:12+0000",
      "dateStarted": "2021-02-09T14:22:12+0000",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>после repartition распределение более равномерное по времени</p>\n\n</div>"
          }
        ]
      }
    },
    {
      "title": "4.3. Key Salting",
      "text": "%md\n.\n.\n.\nДругой способ исправить неравномерность по ключу -- создание синтетического ключа с равномерным распределением. В нашем случае неравномерность исходит от единственного значения city='BIG_CITY', которое часто повторяется в данных и при группировке попадает к одному экзекьютору. В таком случае лучше провести группировку в два этапа по синтетическому ключу CITY_SALT, который принимает значение BIG_CITY_rand (rand -- случайное целое число) для популярного значения BIG_CITY и CITY для остальных значений. На втором этапе восстанавливаем значения CITY и проводим повторную агрегацию, которая не занимает времени, потому что проводится по существенно меньшего размера данным. \n\nТакая же техника применима и к джойнам по неравномерному ключу, см, например https://itnext.io/handling-data-skew-in-apache-spark-9f56343e58e8\n\nЧто нужно реализовать:\n* добавить синтетический ключ\n* группировка по синтетическому ключу\n* восстановление исходного значения\n* группировка по исходной колонке",
      "user": "anonymous",
      "dateUpdated": "2021-02-05T11:42:32+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<p>.\n<br  />.\n<br  />.\n<br  />Другой способ исправить неравномерность по ключу &ndash; создание синтетического ключа с равномерным распределением. В нашем случае неравномерность исходит от единственного значения city='BIG_CITY', которое часто повторяется в данных и при группировке попадает к одному экзекьютору. В таком случае лучше провести группировку в два этапа по синтетическому ключу CITY_SALT, который принимает значение BIG_CITY_rand (rand &ndash; случайное целое число) для популярного значения BIG_CITY и CITY для остальных значений. На втором этапе восстанавливаем значения CITY и проводим повторную агрегацию, которая не занимает времени, потому что проводится по существенно меньшего размера данным.</p>\n<p>Такая же техника применима и к джойнам по неравномерному ключу, см, например https://itnext.io/handling-data-skew-in-apache-spark-9f56343e58e8</p>\n<p>Что нужно реализовать:</p>\n<ul>\n<li>добавить синтетический ключ</li>\n<li>группировка по синтетическому ключу</li>\n<li>восстановление исходного значения</li>\n<li>группировка по исходной колонке</li>\n</ul>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_467415850",
      "id": "20201128-173534_1924644474",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "status": "READY",
      "$$hashKey": "object:1044"
    },
    {
      "text": "%pyspark\nfrom pyspark.sql.functions import monotonically_increasing_id, when, rand, round, expr, lit, sum, countDistinct\n\nsalt_size = 10\n\nskew_df.withColumn(\"salt_index\", round(100 * rand()) )\\\n.withColumn(\"city_salt\", when(col(\"city\") == \"BIG_CITY\", expr(\"CONCAT(city, salt_index)\")).otherwise(col(\"city\")))\\\n.groupBy(\"city_salt\")\\\n.agg(countDistinct(\"event_id\").alias(\"count\"))\\\n.withColumn(\"city\", when(expr(\"city_salt not like 'SMALL%'\"), lit(\"BIG_CITY\")).otherwise(col(\"city_salt\")))\\\n.groupBy(\"city\")\\\n.agg(sum(\"count\").alias(\"count\"))\\\n.orderBy(col(\"count\"), ascending=False)\\\n.show()\n",
      "user": "393_burmistrova",
      "dateUpdated": "2021-02-09T14:23:27+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://bigdataanalytics-head-0.novalocal:4042/jobs/job?id=7",
              "$$hashKey": "object:6207"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612880574952_76917069",
      "id": "paragraph_1612880574952_76917069",
      "dateCreated": "2021-02-09T14:22:54+0000",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:6089",
      "dateFinished": "2021-02-09T14:26:05+0000",
      "dateStarted": "2021-02-09T14:23:27+0000",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+-------------+--------+\n|         city|   count|\n+-------------+--------+\n|     BIG_CITY|17999446|\n|SMALL_CITY_71|   20477|\n|SMALL_CITY_61|   20278|\n|SMALL_CITY_90|   20261|\n|SMALL_CITY_76|   20261|\n|SMALL_CITY_99|   20247|\n|SMALL_CITY_87|   20223|\n|SMALL_CITY_96|   20211|\n|SMALL_CITY_25|   20205|\n|SMALL_CITY_86|   20193|\n|SMALL_CITY_36|   20173|\n|SMALL_CITY_67|   20167|\n|SMALL_CITY_28|   20165|\n|SMALL_CITY_44|   20164|\n|SMALL_CITY_22|   20163|\n|SMALL_CITY_19|   20157|\n|SMALL_CITY_18|   20152|\n|SMALL_CITY_38|   20151|\n|SMALL_CITY_52|   20138|\n|SMALL_CITY_56|   20136|\n+-------------+--------+\nonly showing top 20 rows\n\n"
          }
        ]
      }
    },
    {
      "text": "spark.stop",
      "user": "393_burmistrova",
      "dateUpdated": "2021-02-09T14:26:44+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1612525352446_1200659311",
      "id": "20201128-174934_1428813475",
      "dateCreated": "2021-02-05T11:42:32+0000",
      "status": "FINISHED",
      "$$hashKey": "object:1045",
      "dateFinished": "2021-02-09T14:26:54+0000",
      "dateStarted": "2021-02-09T14:26:47+0000"
    }
  ],
  "name": "hw_2",
  "id": "2FZSYHQUK",
  "defaultInterpreterGroup": "spark",
  "version": "0.9.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {},
  "path": "/393_Burmistrova/hw_2"
}