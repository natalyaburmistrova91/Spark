{
  "metadata": {
    "name": "HW_1",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \r\n\r\nДомашнее задание 1\r\n\r\nhttps://s3.amazonaws.com/apache-zeppelin/tutorial/bank/bank.csv\r\n\r\n1. Построить распределения клиентов по возрастам\r\n2. Распределение по возрасту с динамическим численным параметром\r\nmax_age\r\n3. Распределение по возрасту с динамическим параметром “marital”\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "spark.table(\"homework.bank\").show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf \u003d sqlContext.table(\"homework.bank\")"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nz.show(df)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nz.show(df[df[\u0027age\u0027] \u003c z.textbox(\"Maximum Age\")])\n"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nz.show(df[df[\u0027marital\u0027] \u003d\u003d z.select(\"status\", [(\"married\",\"Married\"),\n                                    (\"single\",\"Single\"),\n                                    (\"devorced\",\"Devorced\")])])\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Домашнее задание 2\nFire Station onboarding\n● What were all the different types of fire calls in 2018?\n● What months within the year 2018 saw the highest number of fire calls?\n● Which neighborhood in San Francisco generated the most fire calls in 2018?\n● Which neighborhoods had the worst response times to fire calls in 2018?\n● Which week in the year in 2018 had the most fire calls?\n● Is there a correlation between neighborhood, zip code, and number of fire calls?\n● How can we use Parquet files or SQL tables to store this data and read it back?\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "spark.sql(\"create database bd_393_Burmistrova\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfc_dataset_path \u003d \"/user/admin/sf-fire-calls.csv\""
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfc_schema \u003d \"CallNumber INTEGER, UnitID STRING, IncidentNumber INTEGER, CallType STRING, CallDate Date, WatchDate STRING, CallFinalDisposition STRING, AvailableDtTm STRING, Address STRING, City STRING, Zipcode INTEGER, Battalion STRING, StationArea string, Box string, OriginalPriority STRING, Priority STRING, FinalPriority INTEGER, ALSUnit boolean, CallTypeGroup STRING, NumAlarms INTEGER, UnitType STRING, UnitSequenceInCallDispatch INTEGER, FirePreventionDistrict string, SupervisorDistrict string, Neighborhood STRING, Location STRING, RowID STRING, Delay double\"\n\ndf \u003d spark.read \\\n    .option(\"header\", True) \\\n    .option(\"dateFormat\", \"MM/dd/yyyy\") \\\n    .schema(fc_schema)\\\n    .csv(fc_dataset_path)\n\nprint(df.count())\n\ndf.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nz.show(df)"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf.write.mode(\"overwrite\")\\\n    .saveAsTable(\"bd_393_Burmistrova.fire_calls\")\n\n\nspark.table(\"bd_393_Burmistrova.fire_calls\").printSchema()\n\nspark.table(\"bd_393_Burmistrova.fire_calls\").rdd.getNumPartitions()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "● What were all the different types of fire calls in 2018?\n"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nz.show(\n    spark.sql(\"select CallType from bd_393_Burmistrova.fire_calls WHERE CallDate BETWEEN \u00272018-01-11 00:00:00\u0027 AND \u00272018-12-31 23:59:59\u0027 GROUP BY CallType\")\n    )"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "● What months within the year 2018 saw the highest number of fire calls?\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nz.show(\n    spark.sql(\"select MONTH(CallDate), COUNT(*) from bd_393_Burmistrova.fire_calls WHERE YEAR(CallDate) \u003d 2018 GROUP BY MONTH(CallDate) ORDER BY COUNT(*)\")\n    )\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "● Which neighborhood in San Francisco generated the most fire calls in 2018?\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nz.show(\n    spark.sql(\"select Neighborhood, COUNT(*) from bd_393_Burmistrova.fire_calls WHERE YEAR(CallDate) \u003d 2018 GROUP BY Neighborhood ORDER BY COUNT(*)\")\n    )"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "● Which neighborhoods had the worst response times to fire calls in 2018?\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nz.show(\n    spark.sql(\"select Neighborhood, AVG(Delay) from bd_393_Burmistrova.fire_calls WHERE YEAR(CallDate) \u003d 2018 GROUP BY Neighborhood ORDER BY AVG(Delay)\")\n    )"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "● Which week in the year in 2018 had the most fire calls?\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nz.show(\n    spark.sql(\"select DAYOFWEEK(CallDate), COUNT(*) from bd_393_Burmistrova.fire_calls WHERE YEAR(CallDate) \u003d 2018 GROUP BY DAYOFWEEK(CallDate) ORDER BY COUNT(*)\")\n    )"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "● Is there a correlation between neighborhood, zip code, and number of fire calls?\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nz.show(\n    spark.sql(\"select Neighborhood, Zipcode, COUNT(*), MONTH(CallDate) from bd_393_Burmistrova.fire_calls GROUP BY MONTH(CallDate), Neighborhood, Zipcode  ORDER BY Neighborhood, Zipcode\")\n    )"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "How can we use Parquet files or SQL tables to store this data and read it back?\n\ndf.write.parquet(\"df.parquet\")\ndf \u003d spark.read.parquet(\"df.parquet\")\n\ndf.write.mode(\"overwrite\")\\\n    .saveAsTable(\"__.__\")\nz.show(spark.sql(\"select * from __.__ \"))"
    }
  ]
}